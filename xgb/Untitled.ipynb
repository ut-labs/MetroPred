{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##10分钟进出站人数统计\n",
    "def status_sum(df_data, lineID=None, stationID=None):\n",
    "    df_copy = df_data.copy().set_index('time')\n",
    "    \n",
    "    series_status1 = None\n",
    "    series_status0 = None\n",
    "    dict_series = {}\n",
    "    \n",
    "    if lineID != None:\n",
    "        df_copy = df_copy[df_copy.lineID == lineID]\n",
    "        dict_series['lineID'] = lineID\n",
    "    if stationID != None:\n",
    "        df_copy = df_copy[df_copy.stationID == stationID]\n",
    "        dict_series['stationID'] = stationID\n",
    "    \n",
    "    series_resample = df_copy['status'].resample('10min', closed='left')\n",
    "    series_status1 = series_resample.sum()\n",
    "    series_status0 = series_resample.count() - series_status1\n",
    "    dict_series.update({'outNums':series_status0, 'inNums':series_status1})\n",
    "    return pd.DataFrame(dict_series)\n",
    "\n",
    "##将时间戳转换为顺序序列\n",
    "def time_convert_to_index(df_data):\n",
    "    str_date = df_data.time[0].strftime('%Y-%m-%d')\n",
    "    range_time = pd.date_range(str_date, periods = 144, freq='10min')\n",
    "    dict_timestamp = {}\n",
    "    for n_index, i in enumerate(range_time):\n",
    "        dict_timestamp[i] = n_index\n",
    "    df_copy = df_data.copy()\n",
    "    df_copy['time_index'] = df_copy['time'].apply(lambda x: dict_timestamp[x])\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../dataset/Metro_train'\n",
    "df_train = pd.read_csv(os.path.join(data_path, 'record_2019-01-01.csv'))\n",
    "# train.head()\n",
    "\n",
    "##换乘点数据\n",
    "metromap_path = '../dataset/'\n",
    "metromap = pd.read_csv(os.path.join(metromap_path, 'Metro_roadMap.csv'), index_col=0)\n",
    "list_joint = []\n",
    "for i in range(81):\n",
    "    list_joint.append('joint_' + str(i))\n",
    "metromap.columns = list_joint\n",
    "\n",
    "##时间戳onehot\n",
    "df_time_index = pd.DataFrame(np.eye(144, dtype=np.uint8))\n",
    "list_time = []\n",
    "for i in range(144):\n",
    "    list_time.append('time_index_' + str(i))\n",
    "df_time_index.columns = list_time\n",
    "df_time_index.head()\n",
    "\n",
    "##星期onehot\n",
    "df_weekday_onehot = pd.DataFrame(np.eye(7, dtype=np.uint8))\n",
    "    \n",
    "list_weekday = []\n",
    "for i in range(1, 8):\n",
    "    list_weekday.append('week_' + str(i))\n",
    "df_weekday_onehot.columns = list_weekday\n",
    "\n",
    "\n",
    "##地铁站点和线路onehot\n",
    "list_lineID = []\n",
    "for i in sorted(df_train.lineID.unique()):\n",
    "    list_lineID.append('lineID_' + str(i))\n",
    "for i in sorted(df_train.stationID.unique()):\n",
    "    list_lineID.append('stationID_' + str(i))\n",
    "\n",
    "columns_train = list_joint + list_time + list_weekday + list_lineID\n",
    "# columns_train\n",
    "\n",
    "del df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = 'Metro_train'\n",
    "# train = pd.read_csv(os.path.join(data_path, 'record_2019-01-01.csv'))\n",
    "# train.head()\n",
    "\n",
    "\n",
    "def process_single_file(filename):\n",
    "    ##文件读取\n",
    "    train = pd.read_csv(filename)\n",
    "    ##时间格式转换\n",
    "    train['time'] = pd.to_datetime(train['time'], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "    ##10分钟各个站点进出人数\n",
    "    df_train = pd.DataFrame()\n",
    "    for i in sorted(train.stationID.unique()):\n",
    "        df_train = df_train.append(status_sum(train, None, i).reset_index(), ignore_index=True)\n",
    "    \n",
    "    ##添加时间序列\n",
    "    df_train = time_convert_to_index(df_train)\n",
    "    \n",
    "    ##星期转换\n",
    "    df_train['weekdays'] = df_train['time'].dt.dayofweek\n",
    "    \n",
    "    ##线路ID补全\n",
    "    dict_lineID = train.drop_duplicates('stationID', 'first')[['lineID', 'stationID']].set_index('stationID').to_dict()['lineID']\n",
    "    df_train['lineID'] = df_train['stationID'].apply(lambda x: dict_lineID[x])\n",
    "    \n",
    "    ##星期onehot\n",
    "    df_train = df_train.merge(df_weekday_onehot, left_on='weekdays', right_index=True)\n",
    "    \n",
    "    ##地铁换乘点数据添加\n",
    "    df_train = df_train.merge(metromap, left_on='stationID', right_index=True)\n",
    "\n",
    "    ##地铁站点和线路onehot\n",
    "    df_tmp = df_train.copy()\n",
    "    df_train = pd.get_dummies(df_tmp, columns=['lineID', 'stationID'])\n",
    "    \n",
    "    \n",
    "    ##时间戳onehot\n",
    "    df_train = df_train.merge(df_time_index, left_on='time_index', right_index=True)\n",
    "    \n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../dataset/Metro_train/record_2019-01-01.csv',\n",
       " '../dataset/Metro_train/record_2019-01-02.csv',\n",
       " '../dataset/Metro_train/record_2019-01-03.csv',\n",
       " '../dataset/Metro_train/record_2019-01-04.csv',\n",
       " '../dataset/Metro_train/record_2019-01-05.csv',\n",
       " '../dataset/Metro_train/record_2019-01-06.csv',\n",
       " '../dataset/Metro_train/record_2019-01-07.csv',\n",
       " '../dataset/Metro_train/record_2019-01-08.csv',\n",
       " '../dataset/Metro_train/record_2019-01-09.csv',\n",
       " '../dataset/Metro_train/record_2019-01-10.csv',\n",
       " '../dataset/Metro_train/record_2019-01-11.csv',\n",
       " '../dataset/Metro_train/record_2019-01-12.csv',\n",
       " '../dataset/Metro_train/record_2019-01-13.csv',\n",
       " '../dataset/Metro_train/record_2019-01-14.csv',\n",
       " '../dataset/Metro_train/record_2019-01-15.csv',\n",
       " '../dataset/Metro_train/record_2019-01-16.csv',\n",
       " '../dataset/Metro_train/record_2019-01-17.csv',\n",
       " '../dataset/Metro_train/record_2019-01-18.csv',\n",
       " '../dataset/Metro_train/record_2019-01-19.csv',\n",
       " '../dataset/Metro_train/record_2019-01-20.csv',\n",
       " '../dataset/Metro_train/record_2019-01-21.csv',\n",
       " '../dataset/Metro_train/record_2019-01-22.csv',\n",
       " '../dataset/Metro_train/record_2019-01-23.csv',\n",
       " '../dataset/Metro_train/record_2019-01-24.csv',\n",
       " '../dataset/Metro_train/record_2019-01-25.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_filepath = []\n",
    "for root, dirs, files in os.walk(data_path):\n",
    "    for n_index, file in enumerate(sorted(files)):\n",
    "        list_filepath.append(os.path.join(root, file))\n",
    "list_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13c0eb346d14d418aa49dff5e2d71df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ../dataset/Metro_train/record_2019-01-02.csv\n",
      "1 ../dataset/Metro_train/record_2019-01-03.csv\n",
      "2 ../dataset/Metro_train/record_2019-01-04.csv\n",
      "3 ../dataset/Metro_train/record_2019-01-05.csv\n",
      "4 ../dataset/Metro_train/record_2019-01-06.csv\n",
      "5 ../dataset/Metro_train/record_2019-01-07.csv\n",
      "6 ../dataset/Metro_train/record_2019-01-08.csv\n",
      "7 ../dataset/Metro_train/record_2019-01-09.csv\n",
      "8 ../dataset/Metro_train/record_2019-01-10.csv\n",
      "9 ../dataset/Metro_train/record_2019-01-11.csv\n",
      "10 ../dataset/Metro_train/record_2019-01-12.csv\n",
      "11 ../dataset/Metro_train/record_2019-01-13.csv\n",
      "12 ../dataset/Metro_train/record_2019-01-14.csv\n",
      "13 ../dataset/Metro_train/record_2019-01-15.csv\n",
      "14 ../dataset/Metro_train/record_2019-01-16.csv\n",
      "15 ../dataset/Metro_train/record_2019-01-17.csv\n",
      "16 ../dataset/Metro_train/record_2019-01-18.csv\n",
      "17 ../dataset/Metro_train/record_2019-01-19.csv\n",
      "18 ../dataset/Metro_train/record_2019-01-20.csv\n",
      "19 ../dataset/Metro_train/record_2019-01-21.csv\n",
      "20 ../dataset/Metro_train/record_2019-01-22.csv\n",
      "21 ../dataset/Metro_train/record_2019-01-23.csv\n",
      "22 ../dataset/Metro_train/record_2019-01-24.csv\n",
      "23 ../dataset/Metro_train/record_2019-01-25.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train_set = pd.DataFrame()\n",
    "df_temp1 = process_single_file(list_filepath[0])\n",
    "for n_index, file in tqdm_notebook(enumerate(list_filepath[1:])):\n",
    "    print(n_index, file)\n",
    "    \n",
    "    df_temp2= process_single_file(file)\n",
    "    df_temp1['next_day'] = df_temp1['time'] + pd.Timedelta(1, 'D')\n",
    "    df_temp3 = df_temp1.merge(df_temp2[['time', 'inNums', 'outNums']],\n",
    "                    left_on='next_day', right_on='time',\n",
    "                    suffixes=(\"\", \"_pre\"))\n",
    "    \n",
    "    df_train_set = df_train_set.append(df_temp3, ignore_index=True)\n",
    "    df_temp1 = df_temp2\n",
    "\n",
    "del df_temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train_set[columns_train + ['inNums']]\n",
    "y_train = df_train_set['inNums_pre'].values\n",
    "\n",
    "del df_train_set\n",
    "\n",
    "# y_train[0]\n",
    "xgb_params = { 'booster':'gblinear','eval_metric': 'mae', 'silent': True, 'nthread': 4}\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    \n",
    "    trn_data = xgb.DMatrix(X_train.iloc[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train.iloc[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    clf = xgb.train(dtrain=trn_data, num_boost_round=20000,\n",
    "                    evals=watchlist, early_stopping_rounds=200, \n",
    "                    verbose_eval=100, params=xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
